"""
Celery tasks for webhook event processing.
"""
import asyncio
from typing import Dict, Any
from pathlib import Path
import tempfile

from app.workers.celery_app import celery_app
from app.models.clip_model import CLIPEmbedder
from app.db.qdrant import QdrantManager
from app.db.postgres import get_session, create_product, update_product, delete_product, get_product_by_external_id
from app.utils.bakai_s3_client import BakaiS3Client
from app.config import settings
from loguru import logger


@celery_app.task(name="process_product_created", bind=True, max_retries=3)
def process_product_created(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞.
    
    Args:
        event_data: –î–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        product_id = event_data["product_id"]
        logger.info(f"üì¶ Processing product.created: {product_id}")
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å async –æ–±—Ä–∞–±–æ—Ç–∫—É
        result = asyncio.run(_process_product_created_async(event_data))
        
        logger.success(f"‚úÖ Product created: {product_id}")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Failed to process product.created: {e}")
        # Retry with exponential backoff
        raise self.retry(exc=e, countdown=2 ** self.request.retries)


async def _process_product_created_async(event_data: Dict[str, Any]) -> Dict[str, Any]:
    """Async –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞."""
    product_id = event_data["product_id"]
    image_key = event_data.get("image_key")
    
    if not image_key:
        logger.warning(f"‚ö†Ô∏è  No image_key for product {product_id}")
        return {"status": "skipped", "reason": "no_image"}
    
    # 1. –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ S3
    s3_client = BakaiS3Client()
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp_file:
        success = s3_client.download_file(
            bucket_name="product-images",
            object_key=image_key,
            local_path=temp_file.name
        )
        
        if not success:
            logger.error(f"‚ùå Failed to download image: {image_key}")
            return {"status": "error", "reason": "download_failed"}
        
        temp_path = temp_file.name
    
    try:
        # 2. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥
        embedder = CLIPEmbedder()
        embedding = await embedder.generate_embedding(temp_path)
        
        if embedding is None:
            logger.error(f"‚ùå Failed to generate embedding for {product_id}")
            return {"status": "error", "reason": "embedding_failed"}
        
        # 3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ PostgreSQL
        image_url = s3_client.generate_presigned_url(
            bucket_name="product-images",
            object_key=image_key,
            expiration=31536000  # 1 –≥–æ–¥
        )
        
        async with get_session() as session:
            await create_product(session, {
                "external_id": f"bakai_{product_id}",
                "title": event_data.get("title", f"Product {product_id}"),
                "description": event_data.get("description", ""),
                "category": event_data.get("category", "bakai"),
                "price": event_data.get("price"),
                "currency": event_data.get("currency", "KGS"),
                "image_url": image_url,
                "product_metadata": {
                    "source": "webhook",
                    "product_id": product_id,
                    "s3_key": image_key,
                    **event_data.get("metadata", {})
                }
            })
        
        # 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Qdrant
        qdrant = QdrantManager()
        await qdrant.upsert_vectors(
            product_ids=[f"bakai_{product_id}"],
            vectors=[embedding.tolist()],
            payloads=[{
                "product_id": f"bakai_{product_id}",
                "source": "webhook",
                "original_id": product_id
            }]
        )
        
        return {
            "status": "success",
            "product_id": product_id,
            "message": "Product created and indexed"
        }
        
    finally:
        # –£–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        try:
            Path(temp_path).unlink()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Failed to delete temp file: {e}")


@celery_app.task(name="process_product_updated", bind=True, max_retries=3)
def process_product_updated(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞.
    
    Args:
        event_data: –î–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        product_id = event_data["product_id"]
        logger.info(f"üîÑ Processing product.updated: {product_id}")
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å async –æ–±—Ä–∞–±–æ—Ç–∫—É
        result = asyncio.run(_process_product_updated_async(event_data))
        
        logger.success(f"‚úÖ Product updated: {product_id}")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Failed to process product.updated: {e}")
        raise self.retry(exc=e, countdown=2 ** self.request.retries)


async def _process_product_updated_async(event_data: Dict[str, Any]) -> Dict[str, Any]:
    """Async –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞."""
    product_id = event_data["product_id"]
    external_id = f"bakai_{product_id}"
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–æ–≤–∞—Ä
    async with get_session() as session:
        product = await get_product_by_external_id(session, external_id)
        
        if not product:
            logger.warning(f"‚ö†Ô∏è  Product not found, creating: {product_id}")
            # –ï—Å–ª–∏ —Ç–æ–≤–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ
            return await _process_product_created_async(event_data)
        
        # –û–±–Ω–æ–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL
        update_data = {}
        
        if "title" in event_data:
            update_data["title"] = event_data["title"]
        if "description" in event_data:
            update_data["description"] = event_data["description"]
        if "category" in event_data:
            update_data["category"] = event_data["category"]
        if "price" in event_data:
            update_data["price"] = event_data["price"]
        if "currency" in event_data:
            update_data["currency"] = event_data["currency"]
        
        if update_data:
            await update_product(session, external_id, update_data)
        
        # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
        image_key = event_data.get("image_key")
        if image_key:
            logger.info(f"üñºÔ∏è  Re-indexing image for {product_id}")
            # –í—ã–∑–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ (–ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é)
            return await _process_product_created_async(event_data)
        
        return {
            "status": "success",
            "product_id": product_id,
            "message": "Product metadata updated"
        }


@celery_app.task(name="process_product_deleted", bind=True, max_retries=3)
def process_product_deleted(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ —É–¥–∞–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞.
    
    Args:
        event_data: –î–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        product_id = event_data["product_id"]
        logger.info(f"üóëÔ∏è  Processing product.deleted: {product_id}")
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å async –æ–±—Ä–∞–±–æ—Ç–∫—É
        result = asyncio.run(_process_product_deleted_async(event_data))
        
        logger.success(f"‚úÖ Product deleted: {product_id}")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Failed to process product.deleted: {e}")
        raise self.retry(exc=e, countdown=2 ** self.request.retries)


async def _process_product_deleted_async(event_data: Dict[str, Any]) -> Dict[str, Any]:
    """Async –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞."""
    product_id = event_data["product_id"]
    external_id = f"bakai_{product_id}"
    
    # 1. –£–¥–∞–ª–∏—Ç—å –∏–∑ PostgreSQL
    async with get_session() as session:
        deleted = await delete_product(session, external_id)
        
        if not deleted:
            logger.warning(f"‚ö†Ô∏è  Product not found in PostgreSQL: {product_id}")
    
    # 2. –£–¥–∞–ª–∏—Ç—å –∏–∑ Qdrant
    qdrant = QdrantManager()
    try:
        await qdrant.delete_vectors([external_id])
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Failed to delete from Qdrant: {e}")
    
    return {
        "status": "success",
        "product_id": product_id,
        "message": "Product deleted from all databases"
    }


@celery_app.task(name="process_product_image_updated", bind=True, max_retries=3)
def process_product_image_updated(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞.
    
    Args:
        event_data: –î–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        product_id = event_data["product_id"]
        logger.info(f"üñºÔ∏è  Processing product.image.updated: {product_id}")
        
        # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Ç–æ –∂–µ —á—Ç–æ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ)
        result = asyncio.run(_process_product_created_async(event_data))
        
        logger.success(f"‚úÖ Product image updated: {product_id}")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Failed to process product.image.updated: {e}")
        raise self.retry(exc=e, countdown=2 ** self.request.retries)

