#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ BakaiMarket S3.

–£–ª—É—á—à–µ–Ω–∏—è:
- –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—ç–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞)
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
- –õ—É—á—à–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
- –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —Å ETA
"""
import asyncio
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm
import time
from PIL import Image
import io

sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from app.utils.bakai_s3_client import BakaiS3Client
from app.models.clip_model import CLIPEmbedder
from app.db.qdrant import QdrantManager
from app.db import get_session, create_product
from app.config import settings
from sqlalchemy import select, text
from app.db.postgres import Product


# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BUCKET_NAME = "product-images"
STORAGE_PATH = Path("/tmp/bakai_products")
BATCH_SIZE = 32  # –†–∞–∑–º–µ—Ä batch –¥–ª—è CLIP
QDRANT_BATCH_SIZE = 1000  # –†–∞–∑–º–µ—Ä batch –¥–ª—è Qdrant
MIN_IMAGE_SIZE = 50  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (px)
MAX_IMAGE_SIZE = 20 * 1024 * 1024  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (20MB)
MAX_DIMENSION = 2048  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∂–∏–º–∞—Ç—å –±–æ–ª—å—à–µ)


def extract_product_id(object_key: str) -> str:
    """–ò–∑–≤–ª–µ—á—å ID —Ç–æ–≤–∞—Ä–∞ –∏–∑ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É."""
    parts = object_key.split('/')
    if len(parts) >= 2:
        return parts[0]
    return "unknown"


def is_main_image(object_key: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–≤–Ω—ã–º (–ø–µ—Ä–≤—ã–º)."""
    filename = Path(object_key).stem
    
    if filename.endswith('_1'):
        return True
    
    if not any(filename.endswith(f'_{i}') for i in range(2, 10)):
        return True
    
    return False


def validate_image(image_data: bytes, product_id: str) -> Optional[Image.Image]:
    """
    –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
    
    Args:
        image_data: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        product_id: ID —Ç–æ–≤–∞—Ä–∞
        
    Returns:
        PIL Image –µ—Å–ª–∏ –≤–∞–ª–∏–¥–Ω–æ, None –µ—Å–ª–∏ –Ω–µ—Ç
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        if len(image_data) > MAX_IMAGE_SIZE:
            logger.warning(f"‚ö†Ô∏è  –¢–æ–≤–∞—Ä {product_id}: —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({len(image_data)} bytes)")
            return None
        
        if len(image_data) < 1000:  # –ú–µ–Ω—å—à–µ 1KB - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
            logger.warning(f"‚ö†Ô∏è  –¢–æ–≤–∞—Ä {product_id}: —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π ({len(image_data)} bytes)")
            return None
        
        # –û—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = Image.open(io.BytesIO(image_data))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
        width, height = img.size
        if width < MIN_IMAGE_SIZE or height < MIN_IMAGE_SIZE:
            logger.warning(f"‚ö†Ô∏è  –¢–æ–≤–∞—Ä {product_id}: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ ({width}x{height})")
            return None
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º JPEG, PNG, WEBP)
        if img.format not in ['JPEG', 'JPG', 'PNG', 'WEBP']:
            logger.warning(f"‚ö†Ô∏è  –¢–æ–≤–∞—Ä {product_id}: –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç ({img.format})")
            return None
        
        # –°–∂–∞—Ç—å –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ –∏ —É—Å–∫–æ—Ä–µ–Ω–∏—è CLIP)
        width, height = img.size
        if width > MAX_DIMENSION or height > MAX_DIMENSION:
            # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ
            img.thumbnail((MAX_DIMENSION, MAX_DIMENSION), Image.Resampling.LANCZOS)
            logger.info(f"   –¢–æ–≤–∞—Ä {product_id}: —Å–∂–∞—Ç–æ —Å {width}x{height} –¥–æ {img.size[0]}x{img.size[1]}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ RGB (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å JPEG –∏ CLIP)
        # RGBA (PNG —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é), P (–ø–∞–ª–∏—Ç—Ä–∞), LA (grayscale + alpha) -> RGB
        if img.mode in ('RGBA', 'LA', 'P', 'PA'):
            # –°–æ–∑–¥–∞—Ç—å –±–µ–ª—ã–π —Ñ–æ–Ω –¥–ª—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏
            rgb_img = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            rgb_img.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA', 'PA') else None)
            img = rgb_img
        elif img.mode != 'RGB':
            img = img.convert('RGB')
        
        return img
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  –¢–æ–≤–∞—Ä {product_id}: –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - {e}")
        return None


async def get_existing_products() -> set:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ PostgreSQL."""
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ –ë–î...")
    
    existing = set()
    
    try:
        async with get_session() as session:
            result = await session.execute(
                select(Product.external_id).where(
                    Product.external_id.like('bakai_%')
                )
            )
            
            for row in result:
                # –ò–∑–≤–ª–µ—á—å ID –∏–∑ external_id (bakai_123 -> 123)
                external_id = row[0]
                product_id = external_id.replace('bakai_', '')
                existing.add(product_id)
        
        logger.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(existing)}")
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤: {e}")
    
    return existing


async def get_all_product_images(
    s3_client: BakaiS3Client,
    max_products: int = None,
    skip_existing: bool = True
) -> List[Dict]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ S3."""
    logger.info(f"üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ bucket '{BUCKET_NAME}'...")
    
    # –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
    existing_products = await get_existing_products() if skip_existing else set()
    
    all_objects = []
    continuation_token = None
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
    while True:
        try:
            if continuation_token:
                response = s3_client.s3_client.list_objects_v2(
                    Bucket=BUCKET_NAME,
                    MaxKeys=1000,
                    ContinuationToken=continuation_token
                )
            else:
                response = s3_client.s3_client.list_objects_v2(
                    Bucket=BUCKET_NAME,
                    MaxKeys=1000
                )
            
            objects = response.get('Contents', [])
            all_objects.extend(objects)
            
            logger.info(f"   –ü–æ–ª—É—á–µ–Ω–æ: {len(all_objects)} –æ–±—ä–µ–∫—Ç–æ–≤...")
            
            if response.get('IsTruncated'):
                continuation_token = response.get('NextContinuationToken')
            else:
                break
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤: {e}")
            break
    
    logger.success(f"‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(all_objects)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    main_images = []
    products_seen = set()
    skipped = 0
    
    for obj in all_objects:
        key = obj['Key']
        product_id = extract_product_id(key)
        
        # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –≤ –ë–î
        if product_id in existing_products:
            skipped += 1
            continue
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
        if product_id not in products_seen and is_main_image(key):
            main_images.append({
                'product_id': product_id,
                'key': key,
                'size': obj.get('Size', 0),
                'modified': obj.get('LastModified')
            })
            products_seen.add(product_id)
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
            if max_products and len(main_images) >= max_products:
                break
    
    logger.success(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ –≥–ª–∞–≤–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(main_images)} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤)")
    if skipped > 0:
        logger.info(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –≤ –ë–î): {skipped} —Ç–æ–≤–∞—Ä–æ–≤")
    
    return main_images


async def download_and_validate_images(
    s3_client: BakaiS3Client,
    images: List[Dict]
) -> List[Tuple[str, str]]:
    """
    –°–∫–∞—á–∞—Ç—å –∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ S3.
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (product_id, local_path) —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∞–ª–∏–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    logger.info(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    
    STORAGE_PATH.mkdir(parents=True, exist_ok=True)
    
    downloaded = []
    invalid = 0
    
    for img in tqdm(images, desc="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ"):
        product_id = img['product_id']
        key = img['key']
        
        try:
            # –°–∫–∞—á–∞—Ç—å –≤ –ø–∞–º—è—Ç—å
            response = s3_client.s3_client.get_object(Bucket=BUCKET_NAME, Key=key)
            image_data = response['Body'].read()
            
            # –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å
            validated_img = validate_image(image_data, product_id)
            
            if validated_img is None:
                invalid += 1
                continue
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ (–≤—Å–µ–≥–¥–∞ –∫–∞–∫ JPEG –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è)
            filename = Path(key).stem  # –ë–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            local_path = STORAGE_PATH / f"{product_id}_{filename}.jpg"
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ JPEG
            validated_img.save(local_path, 'JPEG', quality=95)
            
            downloaded.append((product_id, str(local_path)))
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {key}: {e}")
            invalid += 1
            continue
    
    logger.success(f"‚úÖ –°–∫–∞—á–∞–Ω–æ –∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ: {len(downloaded)}/{len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    if invalid > 0:
        logger.warning(f"‚ö†Ô∏è  –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {invalid}")
    
    return downloaded


async def generate_embeddings_with_cleanup(
    embedder: CLIPEmbedder,
    images: List[Tuple[str, str]]
) -> List[Tuple[str, List[float]]]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —É–¥–∞–ª—è—Ç—å —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (product_id, embedding)
    """
    logger.info(f"üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    
    embeddings = []
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏
    for i in tqdm(range(0, len(images), BATCH_SIZE), desc="CLIP –æ–±—Ä–∞–±–æ—Ç–∫–∞"):
        batch = images[i:i + BATCH_SIZE]
        
        batch_paths = [img[1] for img in batch]
        batch_ids = [img[0] for img in batch]
        
        try:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –±–∞—Ç—á–µ–º
            batch_embeddings = await embedder.generate_embeddings_batch(batch_paths)
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for product_id, embedding, img_path in zip(batch_ids, batch_embeddings, batch_paths):
                if embedding is not None:
                    embeddings.append((product_id, embedding.tolist()))
                else:
                    logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}")
                
                # –£–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—ç–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞)
                try:
                    Path(img_path).unlink()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {img_path}: {e}")
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ batch: {e}")
            continue
    
    logger.success(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(embeddings)}/{len(images)}")
    
    return embeddings


async def save_to_databases(
    embeddings: List[Tuple[str, List[float]]],
    images: List[Tuple[str, str]]
):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL –∏ Qdrant."""
    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    
    # –°–æ–∑–¥–∞—Ç—å –º–∞–ø–ø–∏–Ω–≥ product_id -> image info
    image_map = {}
    for img in images:
        product_id = img[0]
        image_path = img[1]
        filename = Path(image_path).name
        original_name = filename[len(product_id) + 1:]
        image_key = f"{product_id}/{original_name}"
        
        image_map[product_id] = {
            'path': image_path,
            'key': image_key
        }
    
    # 1. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ PostgreSQL
    logger.info("   PostgreSQL...")
    saved_pg = 0
    s3_client = BakaiS3Client()
    
    async with get_session() as session:
        for product_id, embedding in tqdm(embeddings, desc="PostgreSQL"):
            try:
                # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
                img_info = image_map.get(product_id)
                if not img_info:
                    continue
                
                # –°–æ–∑–¥–∞—Ç—å presigned URL
                image_url = s3_client.generate_presigned_url(
                    BUCKET_NAME,
                    img_info['key'],
                    expiration=31536000  # 1 –≥–æ–¥
                )
                
                # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
                await create_product(session, {
                    "external_id": f"bakai_{product_id}",
                    "title": f"Product {product_id}",
                    "description": f"BakaiMarket product ID: {product_id}",
                    "category": "bakai",
                    "image_url": image_url or f"s3://{BUCKET_NAME}/{img_info['key']}",
                    "product_metadata": {
                        "source": "bakai_s3",
                        "product_id": product_id,
                        "s3_bucket": BUCKET_NAME,
                        "s3_key": img_info['key']
                    }
                })
                
                saved_pg += 1
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ {product_id} –≤ PostgreSQL: {e}")
                continue
    
    logger.success(f"‚úÖ PostgreSQL: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_pg}/{len(embeddings)} —Ç–æ–≤–∞—Ä–æ–≤")
    
    # 2. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Qdrant (–±–∞—Ç—á–∞–º–∏)
    logger.info("   Qdrant...")
    
    qdrant = QdrantManager()
    successful = 0
    failed = 0
    
    total_batches = (len(embeddings) + QDRANT_BATCH_SIZE - 1) // QDRANT_BATCH_SIZE
    
    for i in tqdm(range(0, len(embeddings), QDRANT_BATCH_SIZE), desc="Qdrant", total=total_batches):
        batch = embeddings[i:i + QDRANT_BATCH_SIZE]
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch
            product_ids = [f"bakai_{pid}" for pid, _ in batch]
            vectors = [emb for _, emb in batch]
            payloads = [
                {
                    "product_id": f"bakai_{pid}",
                    "source": "bakai_s3",
                    "original_id": pid
                }
                for pid, _ in batch
            ]
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å batch
            await qdrant.upsert_vectors(
                product_ids=product_ids,
                vectors=vectors,
                payloads=payloads
            )
            
            successful += len(batch)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è batch {i//QDRANT_BATCH_SIZE + 1} –≤ Qdrant: {e}")
            failed += len(batch)
            continue
    
    logger.success(f"‚úÖ Qdrant: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {successful}/{len(embeddings)} –≤–µ–∫—Ç–æ—Ä–æ–≤")
    if failed > 0:
        logger.warning(f"‚ö†Ô∏è  Qdrant: –Ω–µ—É–¥–∞—á–Ω–æ {failed}/{len(embeddings)} –≤–µ–∫—Ç–æ—Ä–æ–≤")


async def main(max_products: int = None, skip_existing: bool = True):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏.
    
    Args:
        max_products: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ (None = –≤—Å–µ)
        skip_existing: –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
    """
    start_time = time.time()
    
    print("\n" + "=" * 70)
    print("  üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
    print("=" * 70)
    
    if max_products:
        print(f"\n‚öôÔ∏è  –†–µ–∂–∏–º: –¢–ï–°–¢ (–ø–µ—Ä–≤—ã–µ {max_products} —Ç–æ–≤–∞—Ä–æ–≤)")
    else:
        print(f"\n‚öôÔ∏è  –†–µ–∂–∏–º: –ü–û–õ–ù–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø (–≤—Å–µ —Ç–æ–≤–∞—Ä—ã)")
    
    print(f"‚öôÔ∏è  –ü—Ä–æ–ø—É—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö: {'–î–ê' if skip_existing else '–ù–ï–¢'}")
    
    # 1. –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    print("\n" + "=" * 70)
    print("üì¶ –®–ê–ì 1: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print("=" * 70)
    
    s3_client = BakaiS3Client()
    images = await get_all_product_images(s3_client, max_products, skip_existing)
    
    if not images:
        print("\n‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏!")
        return
    
    # 2. –°–∫–∞—á–∞—Ç—å –∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("\n" + "=" * 70)
    print("üì• –®–ê–ì 2: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print("=" * 70)
    
    downloaded = await download_and_validate_images(s3_client, images)
    
    if not downloaded:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!")
        return
    
    # 3. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (—Å —É–¥–∞–ª–µ–Ω–∏–µ–º —Ñ–∞–π–ª–æ–≤)
    print("\n" + "=" * 70)
    print("üß† –®–ê–ì 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    print("=" * 70)
    
    embedder = CLIPEmbedder()
    embeddings = await generate_embeddings_with_cleanup(embedder, downloaded)
    
    if not embeddings:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏!")
        return
    
    # 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "=" * 70)
    print("üíæ –®–ê–ì 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 70)
    
    await save_to_databases(embeddings, downloaded)
    
    # –ò—Ç–æ–≥–∏
    elapsed = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("üìä –ò–¢–û–ì–ò")
    print("=" * 70)
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(embeddings)}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.2f} —Å–µ–∫—É–Ω–¥ ({elapsed/60:.2f} –º–∏–Ω—É—Ç)")
    
    if elapsed > 0:
        print(f"üìà –°–∫–æ—Ä–æ—Å—Ç—å: {len(embeddings) / elapsed:.2f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫")
        
        # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        if max_products and max_products < 85337:
            estimated_total = (85337 / len(embeddings)) * elapsed
            print(f"‚è±Ô∏è  –û—Ü–µ–Ω–∫–∞ –¥–ª—è –≤—Å–µ—Ö 85,337 —Ç–æ–≤–∞—Ä–æ–≤: {estimated_total/3600:.2f} —á–∞—Å–æ–≤")
    
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("   1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫: python scripts/test_visual_search.py")
    print("   2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –ë–î")
    
    print("=" * 70 + "\n")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ BakaiMarket S3")
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ (–¥–ª—è —Ç–µ—Å—Ç–∞)"
    )
    parser.add_argument(
        "--no-skip-existing",
        action="store_true",
        help="–ù–µ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–≤–∞—Ä—ã (–∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–Ω–æ–≤–æ)"
    )
    
    args = parser.parse_args()
    
    # Configure logging
    logger.remove()
    logger.add(
        sys.stdout,
        format="<level>{message}</level>",
        level="INFO"
    )
    
    asyncio.run(main(
        max_products=args.limit,
        skip_existing=not args.no_skip_existing
    ))

