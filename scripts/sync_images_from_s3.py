#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ BakaiMarket S3.

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≤ Qdrant.
"""
import asyncio
import sys
from pathlib import Path
from typing import List, Dict, Tuple
from tqdm import tqdm
import time

sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from app.utils.bakai_s3_client import BakaiS3Client
from app.models.clip_model import CLIPEmbedder
from app.db.qdrant import QdrantManager
from app.db import get_session, create_product
from app.config import settings


# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BUCKET_NAME = "product-images"
STORAGE_PATH = Path("/tmp/bakai_products")  # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
BATCH_SIZE = 32  # –†–∞–∑–º–µ—Ä batch –¥–ª—è CLIP


def extract_product_id(object_key: str) -> str:
    """
    –ò–∑–≤–ª–µ—á—å ID —Ç–æ–≤–∞—Ä–∞ –∏–∑ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É.
    
    –ü—Ä–∏–º–µ—Ä—ã:
        1/000101141_1.jpg -> 1
        100/970043.jpg -> 100
        1000/1207843254-17.jpg -> 1000
    
    Args:
        object_key: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ S3
        
    Returns:
        ID —Ç–æ–≤–∞—Ä–∞ (–Ω–æ–º–µ—Ä –ø–∞–ø–∫–∏)
    """
    parts = object_key.split('/')
    if len(parts) >= 2:
        return parts[0]  # –ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å - —ç—Ç–æ ID —Ç–æ–≤–∞—Ä–∞
    return "unknown"


def is_main_image(object_key: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–≤–Ω—ã–º (–ø–µ—Ä–≤—ã–º).
    
    –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ (_1.jpg –∏–ª–∏ –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞).
    
    Args:
        object_key: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ S3
        
    Returns:
        True –µ—Å–ª–∏ —ç—Ç–æ –≥–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    """
    filename = Path(object_key).stem
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å _1 –≤ –∫–æ–Ω—Ü–µ - —ç—Ç–æ –ø–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ
    if filename.endswith('_1'):
        return True
    
    # –ï—Å–ª–∏ –Ω–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å–∞ _N - —Ç–æ–∂–µ –±–µ—Ä–µ–º
    if not any(filename.endswith(f'_{i}') for i in range(2, 10)):
        return True
    
    return False


async def get_all_product_images(
    s3_client: BakaiS3Client,
    max_products: int = None
) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ S3.
    
    Args:
        s3_client: S3 –∫–ª–∏–µ–Ω—Ç
        max_products: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ (None = –≤—Å–µ)
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
    """
    logger.info(f"üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ bucket '{BUCKET_NAME}'...")
    
    all_objects = []
    continuation_token = None
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
    while True:
        try:
            if continuation_token:
                response = s3_client.s3_client.list_objects_v2(
                    Bucket=BUCKET_NAME,
                    MaxKeys=1000,
                    ContinuationToken=continuation_token
                )
            else:
                response = s3_client.s3_client.list_objects_v2(
                    Bucket=BUCKET_NAME,
                    MaxKeys=1000
                )
            
            objects = response.get('Contents', [])
            all_objects.extend(objects)
            
            logger.info(f"   –ü–æ–ª—É—á–µ–Ω–æ: {len(all_objects)} –æ–±—ä–µ–∫—Ç–æ–≤...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if response.get('IsTruncated'):
                continuation_token = response.get('NextContinuationToken')
            else:
                break
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤: {e}")
            break
    
    logger.success(f"‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(all_objects)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    main_images = []
    products_seen = set()
    
    for obj in all_objects:
        key = obj['Key']
        product_id = extract_product_id(key)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
        if product_id not in products_seen and is_main_image(key):
            main_images.append({
                'product_id': product_id,
                'key': key,
                'size': obj.get('Size', 0),
                'modified': obj.get('LastModified')
            })
            products_seen.add(product_id)
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
            if max_products and len(main_images) >= max_products:
                break
    
    logger.success(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ –≥–ª–∞–≤–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(main_images)} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤)")
    
    return main_images


async def download_images(
    s3_client: BakaiS3Client,
    images: List[Dict]
) -> List[Tuple[str, str]]:
    """
    –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ S3.
    
    Args:
        s3_client: S3 –∫–ª–∏–µ–Ω—Ç
        images: –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (product_id, local_path)
    """
    logger.info(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    
    # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è
    STORAGE_PATH.mkdir(parents=True, exist_ok=True)
    
    downloaded = []
    
    for img in tqdm(images, desc="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ"):
        product_id = img['product_id']
        key = img['key']
        
        # –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
        filename = Path(key).name
        local_path = STORAGE_PATH / f"{product_id}_{filename}"
        
        # –°–∫–∞—á–∞—Ç—å
        success = s3_client.download_file(BUCKET_NAME, key, str(local_path))
        
        if success:
            downloaded.append((product_id, str(local_path)))
        else:
            logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å: {key}")
    
    logger.success(f"‚úÖ –°–∫–∞—á–∞–Ω–æ: {len(downloaded)}/{len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    return downloaded


async def generate_embeddings(
    embedder: CLIPEmbedder,
    images: List[Tuple[str, str]]
) -> List[Tuple[str, List[float]]]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    
    Args:
        embedder: CLIP embedder
        images: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (product_id, image_path)
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (product_id, embedding)
    """
    logger.info(f"üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    
    embeddings = []
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏
    for i in tqdm(range(0, len(images), BATCH_SIZE), desc="CLIP –æ–±—Ä–∞–±–æ—Ç–∫–∞"):
        batch = images[i:i + BATCH_SIZE]
        
        batch_paths = [img[1] for img in batch]
        batch_ids = [img[0] for img in batch]
        
        try:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –±–∞—Ç—á–µ–º
            batch_embeddings = await embedder.generate_embeddings_batch(batch_paths)
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for product_id, embedding in zip(batch_ids, batch_embeddings):
                if embedding is not None:
                    embeddings.append((product_id, embedding.tolist()))
                else:
                    logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}")
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ batch: {e}")
            continue
    
    logger.success(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(embeddings)}/{len(images)}")
    
    return embeddings


async def save_to_databases(
    embeddings: List[Tuple[str, List[float]]],
    images: List[Tuple[str, str]]
):
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL –∏ Qdrant.
    
    Args:
        embeddings: –°–ø–∏—Å–æ–∫ (product_id, embedding)
        images: –°–ø–∏—Å–æ–∫ (product_id, image_path)
    """
    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    
    # –°–æ–∑–¥–∞—Ç—å –º–∞–ø–ø–∏–Ω–≥ product_id -> image_path
    image_map = {pid: path for pid, path in images}
    
    # 1. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ PostgreSQL
    logger.info("   PostgreSQL...")
    saved_pg = 0
    
    async with get_session() as session:
        for product_id, embedding in tqdm(embeddings, desc="PostgreSQL"):
            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º presigned URL –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                s3_client = BakaiS3Client()
                image_key = None
                
                # –ù–∞–π—Ç–∏ –∫–ª—é—á –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ S3
                for img in images:
                    if img[0] == product_id:
                        # –ò–∑–≤–ª–µ—á—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–ª—é—á –∏–∑ –ø—É—Ç–∏
                        filename = Path(img[1]).name
                        # –£–±—Ä–∞—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å product_id_
                        original_name = filename[len(product_id) + 1:]
                        image_key = f"{product_id}/{original_name}"
                        break
                
                # –°–æ–∑–¥–∞—Ç—å presigned URL
                image_url = None
                if image_key:
                    image_url = s3_client.generate_presigned_url(
                        BUCKET_NAME,
                        image_key,
                        expiration=31536000  # 1 –≥–æ–¥
                    )
                
                # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
                await create_product(session, {
                    "external_id": f"bakai_{product_id}",
                    "title": f"Product {product_id}",
                    "description": f"BakaiMarket product ID: {product_id}",
                    "category": "bakai",
                    "image_url": image_url or f"s3://{BUCKET_NAME}/{image_key}",
                    "product_metadata": {
                        "source": "bakai_s3",
                        "product_id": product_id,
                        "s3_bucket": BUCKET_NAME,
                        "s3_key": image_key
                    }
                })
                
                saved_pg += 1
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ {product_id} –≤ PostgreSQL: {e}")
                continue
    
    logger.success(f"‚úÖ PostgreSQL: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_pg}/{len(embeddings)} —Ç–æ–≤–∞—Ä–æ–≤")
    
    # 2. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Qdrant (–±–∞—Ç—á–∞–º–∏ —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å timeout)
    logger.info("   Qdrant...")
    
    QDRANT_BATCH_SIZE = 1000  # –ó–∞–≥—Ä—É–∂–∞—Ç—å –ø–æ 1000 –≤–µ–∫—Ç–æ—Ä–æ–≤
    qdrant = QdrantManager()
    
    successful = 0
    failed = 0
    
    total_batches = (len(embeddings) + QDRANT_BATCH_SIZE - 1) // QDRANT_BATCH_SIZE
    
    for i in tqdm(range(0, len(embeddings), QDRANT_BATCH_SIZE), desc="Qdrant", total=total_batches):
        batch = embeddings[i:i + QDRANT_BATCH_SIZE]
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch
            product_ids = [f"bakai_{pid}" for pid, _ in batch]
            vectors = [emb for _, emb in batch]
            payloads = [
                {
                    "product_id": f"bakai_{pid}",
                    "source": "bakai_s3",
                    "original_id": pid
                }
                for pid, _ in batch
            ]
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å batch
            await qdrant.upsert_vectors(
                product_ids=product_ids,
                vectors=vectors,
                payloads=payloads
            )
            
            successful += len(batch)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è batch {i//QDRANT_BATCH_SIZE + 1} –≤ Qdrant: {e}")
            failed += len(batch)
            continue
    
    logger.success(f"‚úÖ Qdrant: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {successful}/{len(embeddings)} –≤–µ–∫—Ç–æ—Ä–æ–≤")
    if failed > 0:
        logger.warning(f"‚ö†Ô∏è  Qdrant: –Ω–µ—É–¥–∞—á–Ω–æ {failed}/{len(embeddings)} –≤–µ–∫—Ç–æ—Ä–æ–≤")


async def main(max_products: int = None):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏.
    
    Args:
        max_products: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ (None = –≤—Å–µ)
    """
    start_time = time.time()
    
    print("\n" + "=" * 70)
    print("  üöÄ –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –ò–ó BAKAI MARKET S3")
    print("=" * 70)
    
    if max_products:
        print(f"\n‚öôÔ∏è  –†–µ–∂–∏–º: –¢–ï–°–¢ (–ø–µ—Ä–≤—ã–µ {max_products} —Ç–æ–≤–∞—Ä–æ–≤)")
    else:
        print(f"\n‚öôÔ∏è  –†–µ–∂–∏–º: –ü–û–õ–ù–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø")
    
    # 1. –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    print("\n" + "=" * 70)
    print("üì¶ –®–ê–ì 1: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print("=" * 70)
    
    s3_client = BakaiS3Client()
    images = await get_all_product_images(s3_client, max_products)
    
    if not images:
        print("\n‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    # 2. –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("\n" + "=" * 70)
    print("üì• –®–ê–ì 2: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print("=" * 70)
    
    downloaded = await download_images(s3_client, images)
    
    if not downloaded:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!")
        return
    
    # 3. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    print("\n" + "=" * 70)
    print("üß† –®–ê–ì 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    print("=" * 70)
    
    embedder = CLIPEmbedder()
    embeddings = await generate_embeddings(embedder, downloaded)
    
    if not embeddings:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏!")
        return
    
    # 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "=" * 70)
    print("üíæ –®–ê–ì 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 70)
    
    await save_to_databases(embeddings, downloaded)
    
    # –ò—Ç–æ–≥–∏
    elapsed = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("üìä –ò–¢–û–ì–ò")
    print("=" * 70)
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(embeddings)}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.2f} —Å–µ–∫—É–Ω–¥ ({elapsed/60:.2f} –º–∏–Ω—É—Ç)")
    print(f"üìà –°–∫–æ—Ä–æ—Å—Ç—å: {len(embeddings) / elapsed:.2f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫")
    
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("   1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫: python scripts/test_search_api.py")
    print("   2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –ë–î")
    print("   3. –ó–∞–ø—É—Å—Ç–∏—Ç—å API –∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –ø–æ —Ñ–æ—Ç–æ")
    
    print("=" * 70 + "\n")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ BakaiMarket S3")
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ (–¥–ª—è —Ç–µ—Å—Ç–∞)"
    )
    
    args = parser.parse_args()
    
    # Configure logging
    logger.remove()
    logger.add(
        sys.stdout,
        format="<level>{message}</level>",
        level="INFO"
    )
    
    asyncio.run(main(max_products=args.limit))

